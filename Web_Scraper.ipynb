{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web-Scraping Recipe Databases",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIHiFE9a11lTxvNdiRs6bt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanushGoel/Gordon-RamsAI/blob/master/Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BtbafQznwZ1"
      },
      "source": [
        "# Food.com V1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLSK5RUNF8N5"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "\n",
        "recipes = []\n",
        "strainer = SoupStrainer()\n",
        "\n",
        "for recipe_num in range(38, 50000):\n",
        "\n",
        "    try:\n",
        "\n",
        "        resp = requests.get(\"https://www.food.com/recipe/low-fat-berry-blue-frozen-dessert-\" + str(recipe_num)) # start url\n",
        "        soup = BeautifulSoup(resp.content, features=\"html.parser\", parse_only=strainer)\n",
        "\n",
        "        ingredients = \"\"\n",
        "        directions = \"\"\n",
        "\n",
        "        for li in soup.find('div', attrs={'class':'recipe-layout__content-left recipe-layout__truncated-element'}).findAll('li'):\n",
        "                \n",
        "            partsContainer = li.findAll('span', attrs={'class':'recipe-ingredients__ingredient-part'})\n",
        "            parts = \"\"\n",
        "            for part in partsContainer:\n",
        "                ingred = part.contents[0].text\n",
        "                if ingred[0] != \",\":\n",
        "                    parts += ingred.strip() + \" \"\n",
        "\n",
        "            ingredients += parts\n",
        "\n",
        "        for li in soup.find('div', attrs={'class':'recipe-layout__content-right recipe-layout__truncated-element'}).findAll('li', attrs={'class':'recipe-directions__step'}):\n",
        "            directions += li.text + \" \"\n",
        "\n",
        "        recipes.append({\n",
        "            \"name\": soup.find('div', attrs={'class':'recipe-title'}).contents[0].text.lower(),\n",
        "            \"ingredients\": ingredients.strip().lower(),\n",
        "            \"directions\": directions.strip().lower(),\n",
        "        })\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "\n",
        "        print(\"number:\", recipe_num)\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "        continue\n",
        "\n",
        "print(len(recipes), \"total recipes scraped\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWVoFKSRDGdh"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "recipes = pd.DataFrame.from_dict(recipes)\n",
        "\n",
        "measure_words = [\"cup\", \"fluid ounce\", \"fl\", \"ounce\", \"tablespoon\", \"teaspoon\", \"t\", \"tb\", \"tsp\",\"tbsp\", \"gill\", \"pint\", \"quart\", \"qt\", \"gallon\", \"ml\", \"milliliter\", \"millilitre\", \"cc\", \"l\", \n",
        "                 \"liter\", \"litre\", \"dl\", \"deciliter\", \"decilitre\", \"pound\", \"lb\", \"ounce\", \"oz\", \"mg\", \"milligram\", \"milligramme\", \"gram\", \"g\", \"gramme\", \"kilogram\", \"kilogramme\", \"kg\"]\n",
        "\n",
        "def remove_measures(text):\n",
        "    text = [word for word in text.split() if word not in measure_words and word not in [item + 's' for item in measure_words] and word not in [item + 'es' for item in measure_words]]\n",
        "    return ' '.join(text)\n",
        "\n",
        "recipes.ingredients = recipes.ingredients.apply(remove_measures)\n",
        "\n",
        "recipes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSIMgku_nsi5"
      },
      "source": [
        "recipes.to_csv(\"recipes_webscraped.csv\", index=False)\n",
        "from google.colab import files\n",
        "files.download(\"recipes_webscraped.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMfJLQyLntN-"
      },
      "source": [
        "# Food.com V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhsDP0Z6uehr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25b94dcf-75b2-486e-c205-67af3a2cd046"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "import concurrent.futures\n",
        "import time\n",
        "\n",
        "recipe_urls = []\n",
        "for recipe_num in range(38, 541006): # first recipe id, last recipe id\n",
        "    recipe_urls.append(\"https://www.food.com/recipe/low-fat-berry-blue-frozen-dessert-\" + str(recipe_num))\n",
        "\n",
        "def scrape(url):\n",
        "\n",
        "        resp = requests.get(url)\n",
        "        soup = BeautifulSoup(resp.content, features=\"html.parser\")\n",
        "\n",
        "        ingredients = \"\"\n",
        "        directions = \"\"\n",
        "\n",
        "        for li in soup.find('div', attrs={'class':'recipe-layout__content-left recipe-layout__truncated-element'}).findAll('li'):\n",
        "                \n",
        "            partsContainer = li.findAll('span', attrs={'class':'recipe-ingredients__ingredient-part'})\n",
        "            parts = \"\"\n",
        "            for part in partsContainer:\n",
        "                ingred = part.contents[0].text\n",
        "                if ingred[0] != \",\":\n",
        "                    parts += ingred.strip() + \" \"\n",
        "\n",
        "            ingredients += parts\n",
        "\n",
        "        for li in soup.find('div', attrs={'class':'recipe-layout__content-right recipe-layout__truncated-element'}).findAll('li', attrs={'class':'recipe-directions__step'}):\n",
        "            directions += li.text + \" \"\n",
        "\n",
        "        return {\"name\": soup.find('div', attrs={'class':'recipe-title'}).contents[0].text.lower(),\n",
        "                \"ingredients\": ingredients.strip().lower(),\n",
        "                \"directions\": directions.strip().lower()}\n",
        "\n",
        "def web_scrape(workers=18):\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "          futures = [executor.submit(scrape, url) for url in recipe_urls]\n",
        "\n",
        "          results = []\n",
        "          for future in concurrent.futures.as_completed(futures):\n",
        "              try:\n",
        "                  results.append(future.result())\n",
        "              except Exception as exc:\n",
        "                  continue\n",
        "\n",
        "    return results\n",
        "\n",
        "t0 = time.time()\n",
        "recipes = web_scrape()\n",
        "t1 = time.time()\n",
        "print(f\"{t1-t0} seconds to parse {len(recipe_urls)} recipes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14728.549757957458 seconds to parse 270503 recipes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFYJhn1x68mH"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "recipes = pd.DataFrame.from_dict(recipes)\n",
        "\n",
        "measure_words = [\"cup\", \"fluid ounce\", \"fl\", \"ounce\", \"tablespoon\", \"teaspoon\", \"t\", \"tb\", \"tsp\",\"tbsp\", \"gill\", \"pint\", \"quart\", \"qt\", \"gallon\", \"ml\", \"milliliter\", \"millilitre\", \"cc\", \"l\", \n",
        "                 \"liter\", \"litre\", \"dl\", \"deciliter\", \"decilitre\", \"pound\", \"lb\", \"ounce\", \"oz\", \"mg\", \"milligram\", \"milligramme\", \"gram\", \"g\", \"gramme\", \"kilogram\", \"kilogramme\", \"kg\", \"pinch\"]\n",
        "\n",
        "def remove_measures(text):\n",
        "    text = ''.join([i for i in str(text) if not i.isdigit()])\n",
        "    text = text.replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\")\n",
        "    text = [word for word in text.split() if word not in measure_words and word not in [item + 's' for item in measure_words] and word not in [item + 'es' for item in measure_words]]\n",
        "    return ' '.join(text)\n",
        "\n",
        "recipes.ingredients = recipes.ingredients.apply(remove_measures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex08WpvszvvP"
      },
      "source": [
        "import nltk\n",
        "!python -m nltk.downloader all -q\n",
        "from textblob import TextBlob\n",
        "\n",
        "def extract_nouns(text):\n",
        "\n",
        "    # \"milk low-fat plain yogurt orange juice banana honey depending on how sweet you like your smoothies pure vanilla extract\" --> \"milk low-fat plain yogurt orange juice banana honey pure vanilla extract\"\n",
        "\n",
        "    return \" \".join(TextBlob(text).noun_phrases)\n",
        "\n",
        "recipes.ingredients = recipes.ingredients.apply(extract_nouns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWjJeFgcRXHp"
      },
      "source": [
        "names = []\n",
        "ingreds = []\n",
        "directions = []\n",
        "\n",
        "for i in range(len(recipes)):\n",
        "\n",
        "    try:\n",
        "        name = recipes.name.iloc[i].encode('utf-8','surrogatepass').decode('utf-8')\n",
        "        ingred = recipes.ingredients.iloc[i].encode('utf-8','surrogatepass').decode('utf-8')\n",
        "        direction = recipes.directions.iloc[i].encode('utf-8','surrogatepass').decode('utf-8')\n",
        "        names.append(name)\n",
        "        ingreds.append(ingred)\n",
        "        directions.append(direction)\n",
        "\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "recipes = pd.DataFrame({\"name\": names, \n",
        "                        \"ingredients\": ingreds,\n",
        "                        \"directions\": directions})\n",
        "\n",
        "del names, ingreds, directions\n",
        "\n",
        "recipes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Gg_qA7U--t"
      },
      "source": [
        "recipes.to_csv(\"recipes_webscraped.csv\", index=False)\n",
        "from google.colab import files\n",
        "files.download(\"recipes_webscraped.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9DdHB9YY3OY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}